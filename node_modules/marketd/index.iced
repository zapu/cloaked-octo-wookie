http = require 'http'
formidable = require 'formidable'
util = require 'util'
fs = require 'fs'
deepequal = require 'deep-equal'

inspectAll = (a) -> util.inspect a, false, null

httpsign = require './httpsign'
Router = require './router'
scheduler = require './scheduler'

torrents = require './torrent_download'
torrents.initTracker()

db = require './couch'

router = new Router()

# Adds route with signed parameters.
# - Each request must have pub_key parameter
# - Each of the fields or files must have correspondent
# "*-signed" parameter with signature (field/file signed 
# with pub_key)

addSignedRoute = (route, cb) ->
	router.addRoute route, (req, res, params, fields, files) ->
		form = new formidable.IncomingForm()
		await form.parse req, defer err, fields, files
		unless httpsign.verifyRequest(req, fields, files)
			res.writeHead 405
			res.end 'Signature error'
			return

		cb(req, res, params, fields, files)

checkKeys = (obj, keys) ->
	for key in keys
		unless key of obj
			return false

	return true

# Error handlers for routes

handleDatabaseError = (res, err) ->
	console.log 'CouchDB error', err
	console.trace()
	res.writeHead 500
	res.end 'Database error'

handleMalformedRequest = (res) ->
	res.writeHead 400
	res.end 'Malformed request'

server = http.createServer (request, response) ->
	unless router.routeRequest request, response
		response.writeHead 404
		response.end "404"

saveAttachmentEx = (db, doc, attachmentName, stream, callback) ->
	writeStream = db.saveAttachment doc, attachmentName, callback
	stream.pipe writeStream


addSignedRoute '/addProject', (req, res, params, fields, files) ->
	return handleMalformedRequest res unless checkKeys(files, ['program']) 	

	programStream = fs.createReadStream files.program.path

	doc = 
		type: 'project'
		pub_key: fields.pub_key
		participants: []
	
	await db.save doc, defer err, dbres
	return handleDatabaseError res, err if err

	await saveAttachmentEx db, { id: dbres._id, rev: dbres._rev },
		{ name: 'program', 'Content-Type': 'application/octet-stream' },
		programStream,	defer err, dbres

	return handleDatabaseError res, err if err	

	delete dbres.headers

	res.writeHead 200
	res.end JSON.stringify dbres

addSignedRoute '/addWork', (req, res, params, fields, files) ->
	return handleMalformedRequest res unless \
		checkKeys(fields, ['project_id']) and 
		checkKeys(files, ['data']) 

	await db.get fields.project_id, defer err, project_doc
	return handleDatabaseError res, err if err

	# TODO: check signature with project.owner (a public key)
	# if fields.pub_key == project_doc.pub_key

	console.log files.data.path

	dataStream = fs.createReadStream files.data.path

	work_doc =
		type: 'work'
		project_id: project_doc._id
		project_rev: project_doc._rev
		results: []
		requests: []
		confirmations: 0

	await db.save work_doc, defer err, dbres
	return handleDatabaseError res, err if err

	await saveAttachmentEx db, { id: dbres._id, rev: dbres._rev },
		{ name: 'data', 'Content-Type': 'application/octet-stream' },
		dataStream,	defer err, dbres

	return handleDatabaseError res, err if err	

	delete dbres.headers

	res.writeHead 200
	res.end JSON.stringify dbres


addSignedRoute '/registerSeller', (req, res, params, fields, files) ->
	await db.view 'market/sellers_by_pub_keys', key: fields.pub_key, defer err, dbres
	if dbres.length > 0
		res.writeHead 400
		res.end 'Seller with this public key already exists'
		return

	seller_doc = 
		type: 'seller'
		pub_key: fields.pub_key

	await db.save seller_doc, defer err, dbres
	return handleDatabaseError res, err if err

	res.writeHead 200
	res.end JSON.stringify dbres

handleSchedulerError = (err, res) ->
	if err.dbError?
		handleDatabaseError res, err
	else if err.logicError?
		res.writeHead 500
		res.end JSON.stringify ok: false, error: err.logicError

addSignedRoute '/getProject', (req, res, params, fields, files) ->
	# find project, send
	# also send work
	await scheduler.getProject db, fields.pub_key, defer err, project
	return handleSchedulerError err, res if err

	res.writeHead 200
	res.end JSON.stringify ok: true, _id: project._id

addSignedRoute '/downloadProject', (req, res, params, fields, files) ->
	return handleMalformedRequest res unless \
		checkKeys(fields, ['project_id'])

	await db.view 'market/projects_with_participants', 
		{ key: [fields.pub_key, fields.project_id] },
		defer err, dbres

	return handleDatabaseError res, err if err

	torrents.makeTorrentFromProgram db, dbres[0].value._id, res

addSignedRoute '/getWork', (req, res, params, fields, files) ->
	return handleMalformedRequest res unless \
		checkKeys(fields, ['project_id'])

	await scheduler.getWork db, fields.pub_key, fields.project_id, defer err, work
	return handleSchedulerError err, res if err

	res.writeHead 200
	res.end JSON.stringify { ok: true, _id: work._id }

getAttachmentEx = (db, doc, attachment, stream, callback) ->
	readStream = db.getAttachment doc, attachment, callback
	readStream.pipe stream

addSignedRoute '/downloadWork', (req, res, params, fields, files) ->
	return handleMalformedRequest res unless \
		checkKeys(fields, ['work_id'])

	res.writeHead 200, 'Content-Type': 'application/octet-stream'

	await getAttachmentEx db, fields.work_id, 'data', res, defer err
	if err
		console.log 'CouchDB getAttachmentEx error', err
		res.end()

	res.end()

addSignedRoute '/submitWork', (req, res, params, fields, files) ->
	return handleMalformedRequest res unless \
		checkKeys(fields, ['work_id']) and 
		checkKeys(files, ['data']) 

	await db.view 'market/work_by_ids', key: fields.work_id, defer err, dbres
	if dbres.length == 0
		res.writeHead 400
		res.end "Work with id #{fields.work_id} does not exist"
		return

	work_doc = dbres[0].value

	await fs.readFile files.program.path, defer err, data
	if err
		console.log 'readFile error', err
		res.writeHead 400
		res.end 'Unable to process attachment'
		return

	confirmations = 0

	if(work_doc.results.length > 0)
		for result in work_doc.results
			if deepequal(JSON.parse(result.data), JSON.parse(data))
				result.confirmations++
				confirmations++
				if(result.confirmations > work_doc.confirmations)
					work_doc.confirmations = result.confirmations

	parse.results.push {
		seller: fields.pub_key
		data
		confirmations
	}

	await db.merge work_doc, defer err, dbres
	return handleDatabaseError res, err if err

	res.writeHead 200
	res.end JSON.stringify dbres

	console.log "#{fields.pub_key} submits work for project: #{work_doc.project_id}, work: #{work_doc._id}, confirmations: #{work_doc.confirmations}"


server.listen 8080, ->
	console.log 'listening'